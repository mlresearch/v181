---
title: On Challenges in Unsupervised Domain Generalization
abstract: Domain Generalization (DG) aims to learn a model from a labeled set of source
  domains which can generalize to an unseen target domain. Although an important stepping
  stone towards building general purpose models, the reliance of DG on labeled source
  data is a problem if we are to deploy scalable ML algorithms in the wild. We thus
  propose to study a novel and more challenging setting which shares the same goals
  as that of DG, but without source labels. We name this setting as Unsupervised Domain
  Generalization (UDG), where the objective is to learn a model from an unlabeled
  set of source domains that can semantically cluster images in an unseen target domain.
  We investigate the challenges involved in solving UDG as well as potential methods
  to address the same. Our experiments indicate that learning a generalizable feature
  representation using self-supervision is a strong baseline for UDG, even outperforming
  sophisticated methods explicitly designed to address domain shift and clustering.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: narayanan22a
month: 0
tex_title: On Challenges in Unsupervised Domain Generalization
firstpage: 42
lastpage: 58
page: 42-58
order: 42
cycles: false
bibtex_author: Narayanan, Vaasudev and Deshmukh, Aniket Anand and Dogan, Urun and
  Balasubramanian, Vineeth N.
author:
- given: Vaasudev
  family: Narayanan
- given: Aniket Anand
  family: Deshmukh
- given: Urun
  family: Dogan
- given: Vineeth N.
  family: Balasubramanian
date: 2022-10-05
address:
container-title: NeurIPS 2021 Workshop on Pre-registration in Machine Learning
volume: '181'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 10
  - 5
pdf: https://proceedings.mlr.press/v181/narayanan22a/narayanan22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
